# Monorepo Guide for Claude Code

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Monorepo Structure

This is a monorepo containing multiple related projects:

| Project | Path | Description |
|---------|------|-------------|
| **Main Server** | `/main-server` | **[NEW]** Consolidated persistent server handling API, database, storage, and GitHub operations |
| **AI Coding Worker** | `/ai-coding-worker` | Provider-agnostic API for executing coding assistant requests with Docker Swarm orchestration |
| **Collaborative Session Worker** | `/collaborative-session-worker` | WebSocket-based real-time collaboration with CRDT synchronization and MinIO persistence |
| **GitHub Worker** | `/github-worker` | *(To be deprecated)* Ephemeral worker for GitHub/Git operations |
| **Storage Worker** | `/storage-worker` | *(To be deprecated)* Storage service for session management with MinIO |
| **Website** | `/website` | Web application with path-based routing and Dokploy deployment |

---

## Main Server (New Architecture)

The Main Server (`/main-server`) consolidates the Website backend, Storage Worker, and GitHub Worker into a single persistent service. This simplifies the architecture and improves performance by reducing inter-service communication.

### Architecture Overview

```
                              FRONTEND
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                         Website (React)                                â”‚
  â”‚  - Chat UI for AI interactions                                        â”‚
  â”‚  - File browser/editor                                                 â”‚
  â”‚  - GitHub OAuth integration                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                              MAIN SERVER
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  (Single persistent service)                                          â”‚
  â”‚                                                                       â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚  â”‚   API Routes    â”‚  â”‚  Storage Layer  â”‚  â”‚  GitHub Layer   â”‚       â”‚
  â”‚  â”‚  - /execute     â”‚  â”‚  - MinIO client â”‚  â”‚  - Clone repos  â”‚       â”‚
  â”‚  â”‚  - /resume      â”‚  â”‚  - File CRUD    â”‚  â”‚  - Create branchâ”‚       â”‚
  â”‚  â”‚  - /sessions    â”‚  â”‚  - Tarball ops  â”‚  â”‚  - Commit/push  â”‚       â”‚
  â”‚  â”‚  - /files       â”‚  â”‚                 â”‚  â”‚  - PR operationsâ”‚       â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                                                                       â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
  â”‚  â”‚  Database Layer â”‚  â”‚ Worker Manager  â”‚                            â”‚
  â”‚  â”‚  - PostgreSQL   â”‚  â”‚  - Spawn workersâ”‚                            â”‚
  â”‚  â”‚  - Drizzle ORM  â”‚  â”‚  - Stream SSE   â”‚                            â”‚
  â”‚  â”‚  - Sessions/msgsâ”‚  â”‚                 â”‚                            â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    Spawn per-request (LLM execution only)
                                    â”‚
                                    â–¼
                       AI CODING WORKER (ephemeral)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  (Simplified - LLM execution only)                                    â”‚
  â”‚  - Receives workspace path from Main Server                           â”‚
  â”‚  - Executes Claude Agent SDK / Codex                                  â”‚
  â”‚  - Streams events back to Main Server                                 â”‚
  â”‚  - NO storage operations                                              â”‚
  â”‚  - NO GitHub operations                                               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Main Server Directory Structure

```
main-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # Express app entrypoint
â”‚   â”œâ”€â”€ auth.ts                     # Lucia authentication
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ env.ts                  # Environment configuration
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ index.ts                # Database connection
â”‚   â”‚   â”œâ”€â”€ schema.ts               # PostgreSQL schema
â”‚   â”‚   â””â”€â”€ schema-sqlite.ts        # SQLite schema
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ execute.ts              # Main /execute endpoint
â”‚   â”‚   â””â”€â”€ resume.ts               # Session replay endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”œâ”€â”€ minioClient.ts      # MinIO client
â”‚   â”‚   â”‚   â””â”€â”€ storageService.ts   # Storage operations
â”‚   â”‚   â””â”€â”€ github/
â”‚   â”‚       â”œâ”€â”€ gitHelper.ts        # Git operations
â”‚   â”‚       â”œâ”€â”€ githubClient.ts     # Repository clone/pull
â”‚   â”‚       â””â”€â”€ operations.ts       # High-level GitHub ops
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ auth.ts                 # Auth middleware
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ claudeAuth.ts           # Claude OAuth helpers
â”‚   â”‚   â”œâ”€â”€ codexAuth.ts            # Codex auth helpers
â”‚   â”‚   â””â”€â”€ llmHelper.ts            # LLM naming helpers
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.ts               # Structured logging
â”‚       â”œâ”€â”€ sessionPathHelper.ts    # Session path utilities
â”‚       â””â”€â”€ emojiMapper.ts          # SSE emoji decoration
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ Dockerfile
```

### Main Server API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check with service status |
| `/api/execute` | POST | Execute AI coding request (SSE) |
| `/api/resume/:sessionId` | GET | Replay stored events (SSE) |
| `/api/sessions/:sessionId/events` | GET | Get all events (JSON) |

### Request Flow (New Architecture)

```
1. Frontend POST /api/execute
   â”‚
2. Main Server: Authenticate, validate request
   â”‚
3. Main Server: Create/update database session
   â”‚
4. Main Server: Check MinIO for existing session
   â”‚
5. If new session:
   â”‚  a. Main Server: Clone repo via GitHub service
   â”‚  b. Main Server: Generate session title/branch via LLM
   â”‚  c. Main Server: Create branch, push
   â”‚  d. Main Server: Store session in MinIO
   â”‚
6. Main Server: Spawn AI Coding Worker
   â”‚  - Pass: workspace path, credentials, user request
   â”‚
7. Main Server: Proxy SSE from AI Worker to Frontend
   â”‚  - Store events to database for replay
   â”‚
8. When AI Worker completes:
   â”‚  a. Main Server: Commit changes via GitHub service
   â”‚  b. Main Server: Push to remote
   â”‚  c. Main Server: Upload session to MinIO
   â”‚
9. Main Server: Update database status, send completion
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3000` | Server port |
| `NODE_ENV` | `development` | Environment mode |
| `DATABASE_URL` | - | PostgreSQL connection string |
| `MINIO_ENDPOINT` | - | MinIO server hostname |
| `MINIO_PORT` | `9000` | MinIO server port |
| `MINIO_ROOT_USER` | - | MinIO access key |
| `MINIO_ROOT_PASSWORD` | - | MinIO secret key |
| `MINIO_BUCKET` | `sessions` | Session storage bucket |
| `AI_WORKER_URL` | `http://localhost:5001` | AI Worker endpoint |
| `WORKSPACE_DIR` | `/workspace` | Base workspace directory |

## Git Commit Message Rules

**MANDATORY REQUIREMENT:** All git commit messages across the entire monorepo MUST follow these rules.

### Format

```
Subject Line [Required]

- Detail Line 1 [Optional]
- Detail Line 2 [Optional]
```

**Important:** There MUST be a blank line between the subject and the detail lines.

### Rules

- Use imperative mood
- Present active tense
- Start with a capital letter
- Start with a verb (Add, Update, Remove, Fix, Refactor, etc)
- **NO prefixes** like `feat:`, `fix:`, `chore:`, `refactor:`, etc.
- **NO emojis**
- Rules apply to both subject line and detail lines
- Details are optional, but include them for larger changes

### Good Examples

```
Add commit-based versioning system
Update API endpoint to support dynamic paths
Fix navigation overlay height issue
```

```
Enhance ColyseusManager and GameRoom for improved room management

- Update ColyseusManager to utilize roomCode from Discord API
- Modify GameRoom to store and log roomCode in metadata
- Ensure fallback behavior when roomCode is not provided
```

### Good Subject Line Verbs

Add, Update, Remove, Fix, Refactor, Enhance, Rename, Move, Extract, Merge, Improve, Optimize, Document

---

## System Architecture

### High-Level Overview

```
                              FRONTEND
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                         Website (React)                                â”‚
  â”‚  - Chat UI for AI interactions                                        â”‚
  â”‚  - File browser/editor                                                 â”‚
  â”‚  - GitHub OAuth integration                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                          Dokploy Reverse Proxy
                                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚                           â”‚
         â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Coding      â”‚       â”‚  GitHub         â”‚       â”‚  Storage        â”‚
â”‚  Worker         â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚  Worker         â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚  Worker         â”‚
â”‚  (port 5001)    â”‚       â”‚  (port 5003)    â”‚       â”‚  (internal)     â”‚
â”‚                 â”‚       â”‚                 â”‚       â”‚                 â”‚
â”‚  10 replicas    â”‚       â”‚  5 replicas     â”‚       â”‚  2 replicas     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚     MinIO       â”‚
                          â”‚  (S3 Storage)   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Worker Responsibilities

| Worker | Purpose | Key Operations |
|--------|---------|----------------|
| **AI Coding Worker** | Execute AI coding requests | - Receive user prompts<br>- Route to provider (Claude/Codex)<br>- Stream SSE responses<br>- Orchestrate GitHub operations |
| **GitHub Worker** | Handle Git operations | - Clone/pull repositories<br>- Create branches (LLM-named)<br>- Commit changes (LLM messages)<br>- Push to remote |
| **Storage Worker** | Manage session persistence | - Store/retrieve sessions<br>- File CRUD operations<br>- Session metadata<br>- Interface to MinIO |

### Request Flow: New Chat Session

```
1. User sends prompt â†’ Website
2. Website â†’ AI Coding Worker: POST /execute
3. AI Coding Worker â†’ GitHub Worker: POST /init-session
   â””â”€â”€ Combines clone + branch creation in one operation
   â””â”€â”€ Uses LLM to generate session title and branch name
   â””â”€â”€ GitHub Worker â†’ Storage Worker: Upload session
4. AI Coding Worker â†’ Claude Agent SDK: Execute user prompt
   â””â”€â”€ Streams SSE events back to Website
5. AI Coding Worker â†’ GitHub Worker: POST /commit-and-push
   â””â”€â”€ Uses LLM to generate commit message from diff
6. AI Coding Worker â†’ Storage Worker: Upload final session state
7. Worker exits (ephemeral model)
```

### Ephemeral Worker Model

AI Coding Worker, GitHub Worker, and Collaborative Session Worker use an ephemeral worker model:

- Workers exit after completing each job (`process.exit(0)` on success)
- Docker Swarm automatically restarts workers after exit
- Provides clean state for each request
- Natural load balancing (idle workers accept new requests)
- Prevents memory leaks over time
- Workers return 429 status when busy

---

## File Management Architecture

**CRITICAL REQUIREMENT:** All file read and write operations MUST go through the **Storage Worker** service.

### Storage Worker as Primary File Interface

The Storage Worker (`/storage-worker`) is the **single source of truth** for all file operations within sessions:

| Operation | Use Storage Worker | Use GitHub API |
|-----------|-------------------|----------------|
| Read file content | Yes | No |
| Write/update file | Yes | No |
| List files | Yes | No |
| Delete file | Yes | No |
| Create commits | No | Yes |
| Create PRs | No | Yes |
| Branch operations | No | Yes |
| AI coding execution | N/A | Via ai-coding-worker |

### Session Path Format

Storage worker uses session paths in the format: `{owner}__{repo}__{branch}` (double underscore separator)

**Important:** Session paths must NOT contain `/` characters. The storage-worker validates this and will reject requests with invalid session paths.

Example: `webedt__monorepo__feature-branch`

### Storage Worker API Endpoints

```
GET    /api/storage-worker/sessions/:sessionPath/files           - List all files
GET    /api/storage-worker/sessions/:sessionPath/files/*         - Read file content
PUT    /api/storage-worker/sessions/:sessionPath/files/*         - Write/update file
DELETE /api/storage-worker/sessions/:sessionPath/files/*         - Delete file
HEAD   /api/storage-worker/sessions/:sessionPath/files/*         - Check if file exists
```

### Frontend API Usage

```typescript
import { storageWorkerApi } from '@/lib/api';

const sessionPath = `${owner}__${repo}__${branch}`;

// Read file
const content = await storageWorkerApi.getFileText(sessionPath, `workspace/${filePath}`);

// Write file
await storageWorkerApi.writeFile(sessionPath, `workspace/${filePath}`, content);

// List files
const files = await storageWorkerApi.listFiles(sessionPath);
```

---

## API Reference

### AI Coding Worker (port 5001)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check with worker status |
| `/status` | GET | Worker idle/busy status |
| `/sessions` | GET | List all sessions |
| `/execute` | POST | Execute AI coding request (SSE) |
| `/abort` | POST | Abort current execution |

### GitHub Worker (port 5003)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check with worker status |
| `/status` | GET | Worker idle/busy status |
| `/clone-repository` | POST | Clone repo into session (SSE) |
| `/init-session` | POST | Clone + create branch combined (SSE) |
| `/create-branch` | POST | Create branch with LLM naming (SSE) |
| `/commit-and-push` | POST | Commit and push changes (SSE) |
| `/create-pull-request` | POST | Create PR on GitHub (SSE) |
| `/merge-pull-request` | POST | Merge existing PR (SSE) |
| `/auto-pull-request` | POST | Full auto-merge workflow (SSE) |

### Storage Worker (internal)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/storage-worker/sessions` | GET | List all sessions |
| `/api/storage-worker/sessions/:path` | GET | Get session metadata |
| `/api/storage-worker/sessions/:path` | HEAD | Check session exists |
| `/api/storage-worker/sessions/:path/upload` | POST | Upload session archive |
| `/api/storage-worker/sessions/:path/download` | GET | Download session archive |
| `/api/storage-worker/sessions/:path/files` | GET | List files in session |
| `/api/storage-worker/sessions/:path/files/*` | GET/PUT/DELETE | File operations |

---

## AI Coding Worker

Provider-agnostic API for executing coding assistant requests with Docker Swarm orchestration.

### Core Components

1. **server.ts** - Express server with SSE streaming endpoints
2. **orchestrator.ts** - Main execution orchestrator
3. **SessionManager** - Manages session persistence
4. **Provider System** - `ClaudeCodeProvider`, `CodexProvider`
5. **emojiMapper** - Centralized emoji assignment for SSE messages

### Request Flow

```
Client â†’ POST /execute
    â†“
server.ts: Check worker status (idle/busy)
    â†“
orchestrator.ts: Validate request, write credentials
    â†“
SessionManager: Download/create session workspace
    â†“
GitHub Worker: Call /init-session (clone + create branch)
    â†“
ProviderFactory: Create provider instance
    â†“
Provider: Execute user request (streaming)
    â†“
SSE events â†’ Client (with emojis applied by emojiMapper)
    â†“
GitHub Worker: Call /commit-and-push (if autoCommit enabled)
    â†“
SessionManager: Upload session to storage
    â†“
Worker exits (ephemeral model)
```

### Authentication

Authentication is passed **per request** via `codingAssistantAuthentication` field:

```json
{
  "codingAssistantAuthentication": "{\"claudeAiOauth\":{\"accessToken\":\"sk-ant-oat01-...\",\"refreshToken\":\"sk-ant-ort01-...\",\"expiresAt\":1763242829010}}"
}
```

The `CredentialManager.writeClaudeCredentials()` writes this to `~/.claude/.credentials.json` for the SDK.

### SSE Event Types

| Event Type | Source | Description |
|------------|--------|-------------|
| `connected` | `ai-coding-worker` | Initial connection with session ID |
| `message` | `ai-coding-worker` | Progress messages |
| `branch_created` | `ai-coding-worker` | Git branch created with session name |
| `session_name` | `ai-coding-worker` | Generated session title and branch name |
| `assistant_message` | `claude-agent-sdk` | Provider output (forwarded from SDK) |
| `commit_progress` | `ai-coding-worker` | Auto-commit progress stages |
| `completed` | `ai-coding-worker` | Job finished with duration |
| `error` | `ai-coding-worker` | Error occurred with code |

### Emoji Mapper (Centralized Emoji Assignment)

The `emojiMapper` utility centralizes all emoji assignment for SSE messages. Sub-workers send semantic stages without emojis, and ai-coding-worker applies appropriate emojis before forwarding to the frontend.

**Stage Emoji Mapping:**

| Stage | Emoji | Description |
|-------|-------|-------------|
| `preparing` | ğŸ”§ | Preparing credentials/initialization |
| `downloading_session` | ğŸ“¥ | Downloading from storage |
| `checking_session` | ğŸ” | Checking for existing session |
| `session_found` | ğŸ“‚ | Existing session found |
| `new_session` | ğŸ†• | Creating new session |
| `cloning` | ğŸ“¥ | Cloning repository |
| `cloned` | âœ… | Clone complete |
| `generating_name` | ğŸ¤– | LLM generating names |
| `name_generated` | âœ¨ | Name generated |
| `creating_branch` | ğŸŒ¿ | Creating git branch |
| `pushing` | ğŸ“¤ | Pushing to remote |
| `uploading` | ğŸ“¤ | Uploading to storage |
| `analyzing` | ğŸ” | Analyzing changes |
| `committing` | ğŸ’¾ | Creating commit |
| `error` | âŒ | Operation failed |

### Image Support

The AI Coding Worker supports sending images to Claude Code along with text prompts:

```json
{
  "userRequest": [
    { "type": "text", "text": "What's in this screenshot?" },
    {
      "type": "image",
      "source": {
        "type": "base64",
        "media_type": "image/png",
        "data": "iVBORw0KGgoAAAANSUhEUg..."
      }
    }
  ]
}
```

Supported formats: `image/jpeg`, `image/png`, `image/gif`, `image/webp`

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `5000` | Server port |
| `WORKSPACE_DIR` | `/workspace` | Session workspace root |
| `DB_BASE_URL` | - | Optional database API URL |

---

## GitHub Worker

Ephemeral worker service for GitHub/Git operations with SSE streaming.

### POST /init-session

Combined operation: clone repository AND create branch with LLM-generated name in a single call. This avoids 429 busy responses that can occur when calling `/clone-repository` and `/create-branch` sequentially.

Request:
```json
{
  "sessionId": "abc123",
  "repoUrl": "https://github.com/owner/repo",
  "branch": "main",
  "userRequest": "Add dark mode toggle",
  "claudeCredentials": "...",
  "githubAccessToken": "ghp_xxx"
}
```

Response (via SSE completed event):
```json
{
  "clonedPath": "repo",
  "branch": "main",
  "wasCloned": true,
  "branchName": "webedt/add-dark-mode-abc12345",
  "sessionTitle": "Add Dark Mode Toggle",
  "sessionPath": "owner__repo__webedt-add-dark-mode-abc12345"
}
```

### POST /commit-and-push

Commit changes with LLM-generated message and push:

```json
{
  "sessionId": "abc123",
  "claudeCredentials": "...",
  "githubAccessToken": "ghp_xxx",
  "userId": "user123"
}
```

### POST /create-pull-request

Create a pull request on GitHub:

```json
{
  "owner": "webedt",
  "repo": "monorepo",
  "title": "Add dark mode feature",
  "head": "feature/dark-mode",
  "base": "main",
  "body": "This PR adds dark mode support",
  "githubAccessToken": "ghp_xxx"
}
```

### POST /auto-pull-request

Complete auto-merge workflow: create PR (or find existing), merge base into feature branch, wait for mergeable status, merge PR, and delete the feature branch.

### SSE Progress Stages

**Init Session:**
`preparing` â†’ `checking_session` â†’ `session_found`/`new_session` â†’ `cloning` â†’ `cloned` â†’ `generating_name` â†’ `name_generated` â†’ `creating_branch` â†’ `pushing` â†’ `uploading`

**Commit and Push:**
`preparing` â†’ `downloading_session` â†’ `analyzing` â†’ `changes_detected` â†’ `generating_message` â†’ `committing` â†’ `pushing` â†’ `uploading`

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `5002` | Server port |
| `TMP_DIR` | `/tmp` | Temporary directory for workspaces |
| `STORAGE_WORKER_URL` | (internal) | URL to storage worker service |

---

## Storage Worker

MinIO-based storage service for session management with file-level access.

### Architecture

Unlike other workers, the Storage Worker is **NOT ephemeral**:
- Runs continuously to handle storage requests
- Maintains persistent connections to MinIO
- Sessions stored as tarball archives (`session.tar.gz`)
- Supports both session-level and file-level operations

### Session Operations

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/storage-worker/sessions` | List all sessions |
| `GET` | `/api/storage-worker/sessions/:sessionPath` | Get session metadata |
| `HEAD` | `/api/storage-worker/sessions/:sessionPath` | Check if session exists |
| `DELETE` | `/api/storage-worker/sessions/:sessionPath` | Delete a session |
| `POST` | `/api/storage-worker/sessions/:sessionPath/upload` | Upload session tarball |
| `GET` | `/api/storage-worker/sessions/:sessionPath/download` | Download session tarball |

### File Operations

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/storage-worker/sessions/:sessionPath/files` | List files in session |
| `GET` | `/api/storage-worker/sessions/:sessionPath/files/*` | Read file content |
| `PUT` | `/api/storage-worker/sessions/:sessionPath/files/*` | Write/update file |
| `DELETE` | `/api/storage-worker/sessions/:sessionPath/files/*` | Delete file |
| `HEAD` | `/api/storage-worker/sessions/:sessionPath/files/*` | Check if file exists |

### Storage Format

Sessions are stored as gzipped tarballs in MinIO:

```
minio/sessions/{sessionPath}/session.tar.gz
â”œâ”€â”€ workspace/              # User workspace files
â”œâ”€â”€ .session-metadata.json  # Session metadata
â””â”€â”€ .stream-events.jsonl    # SSE event log (optional)
```

### On-Demand Session Creation

Sessions are created automatically when you write a file to a non-existent session. No explicit "create session" call is needed.

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3000` | Server port |
| `MINIO_ENDPOINT` | - | MinIO server hostname |
| `MINIO_PORT` | `9000` | MinIO server port |
| `MINIO_ROOT_USER` | - | MinIO access key |
| `MINIO_ROOT_PASSWORD` | - | MinIO secret key |
| `MINIO_BUCKET` | `sessions` | Bucket name for sessions |

---

## Collaborative Session Worker

WebSocket-based collaborative session worker with CRDT synchronization and auto-commit functionality.

### Core Components

1. **WebSocket Server** - Handles client connections and message routing
2. **Session Storage** - MinIO integration for persistent session storage
3. **Collaboration Manager** - CRDT-based conflict-free synchronization using Yjs
4. **Auto-Commit** - Automatic git commits after cooldown period

### Session Lifecycle

1. **Client Connection**: Client connects via WebSocket and joins a session
2. **Session Download**: Worker downloads session from MinIO (if exists)
3. **Collaboration**: Multiple users can edit files simultaneously
4. **Auto-Commit**: After cooldown period with no activity, changes are committed
5. **Session Upload**: On disconnect or cleanup, session is uploaded to MinIO

### Message Types

**Client â†’ Server:**
- `join` - Join a session
- `fileOperation` - Perform file operation (create, update, delete, rename)
- `yjsUpdate` - Yjs CRDT update
- `getFiles` - List files in workspace
- `getFile` - Get file content

**Server â†’ Client:**
- `joined` - Successfully joined session
- `userJoined` / `userLeft` - User events
- `fileOperation` - File operation from another user
- `yjsUpdate` - CRDT update from another user
- `files` / `fileContent` - Response to queries
- `error` - Error message

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `8080` | WebSocket server port |
| `WORKSPACE_DIR` | `/workspace` | Base directory for workspaces |
| `COOLDOWN_MS` | `300000` | Auto-commit cooldown (5 minutes) |

---

## Website

Web application with path-based routing and Dokploy deployment.

### Deployment URLs

This project uses Dokploy for deployments with path-based routing:

```
https://github.etdofresh.com/{owner}/{repo}/{branch}/
```

**Examples:**
- `https://github.etdofresh.com/webedt/monorepo/main/`
- `https://github.etdofresh.com/webedt/monorepo/claude-rename-session-abc123/`

**Pattern:**
- Owner and repo are lowercased
- Branch name preserves original case (slashes replaced with dashes)
- Example: Branch `claude/test-feature` becomes `claude-test-feature`

### Path-Based Routing Requirements

**CRITICAL:** Three files MUST be updated to support path-based routing:

1. **`apps/client/index.html`** - Base tag detection
2. **`apps/client/src/App.tsx`** - React Router basename
3. **`apps/client/src/lib/api.ts`** - API base URL detection

Each file must detect the path-based pattern by checking for 3 path segments:

```javascript
if (pathSegments.length >= 3 && !appRoutes.includes(pathSegments[0])) {
  basePath = `/${pathSegments[0]}/${pathSegments[1]}/${pathSegments[2]}`;
} else {
  basePath = '/';
}
```

### Version Management

Version numbers are **automatically calculated** by GitHub Actions:
- `MAJOR.MINOR.PATCH` where PATCH = commits since tag
- Example: Tag `v1.2.0` + 5 commits = `1.2.5`

### Displaying Links After Tasks

**CRITICAL REQUIREMENT:** After completing ANY task that involves code changes, commits, or pushes in the website project, you MUST ALWAYS display:

```
**Links:**

GitHub Branch: [https://github.com/webedt/monorepo/tree/{branch-name}](https://github.com/webedt/monorepo/tree/{branch-name})
Live Site: [https://github.etdofresh.com/webedt/monorepo/{branch}/](https://github.etdofresh.com/webedt/monorepo/{branch}/)
```

---

## Development Commands

### Common Node.js Patterns

```bash
# Install dependencies
npm install  # or pnpm install

# Run in development mode
npm run dev

# Build TypeScript
npm run build

# Run production build
npm start
```

### Docker Swarm Deployment

```bash
# Initialize swarm (first time only)
docker swarm init

# Deploy stack
docker stack deploy -c swarm.yml {stack-name}

# Monitor deployment
docker service ls
docker service ps {service-name}
docker service logs {service-name} -f

# Scale workers
docker service scale {service-name}=20

# Remove stack
docker stack rm {stack-name}
```

### Testing from Production Server

```bash
# Test via SSH to production server
ssh ehub2023 'curl -s http://127.0.0.1:5001/health | jq'
ssh ehub2023 'curl -s http://127.0.0.1:5003/health | jq'
```

---

## Repository Links

- GitHub: https://github.com/webedt/monorepo
- Issues: https://github.com/webedt/monorepo/issues

---

*Documentation last updated: 2025-12-05*
